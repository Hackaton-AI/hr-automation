# -*- coding: utf-8 -*-
"""Untitled9.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1JSTN7R-xinN0eAXl9H_7Z2MFcyLXjipa
"""

!pip install -q --upgrade pip
!pip install -q --force-reinstall --no-cache-dir \
  "numpy==2.0.2" "pandas==2.2.2" "scipy==1.14.1" \
  "scikit-learn==1.6.1" "joblib==1.4.2" "matplotlib==3.8.4"

import numpy, pandas, scipy, sklearn, joblib, matplotlib
print("NumPy:", numpy.__version__, "| Pandas:", pandas.__version__, "| Sklearn:", sklearn.__version__)
print("✅ Setup OK. Si Colab demande un redémarrage du runtime, accepte puis continue.")

import os, pandas as pd

DEFAULT_PATH = "/content/job_fit_1000_numeric.csv"
if os.path.exists(DEFAULT_PATH):
    DATA_PATH = DEFAULT_PATH
else:
    from google.colab import files
    up = files.upload()  # choisis job_fit_1000_numeric.csv
    DATA_PATH = list(up.keys())[0]

df = pd.read_csv(DATA_PATH)
print("Shape:", df.shape)
df.head(3)

import numpy as np
assert "fit" in df.columns, "Colonne 'fit' manquante."

y = (df["fit"] > 0.5).astype(int)  # cible binaire
num_cols = df.select_dtypes(include=[np.number]).columns.tolist()

# on écarte la cible et quelques colonnes méta si elles existent
drop_cols = [c for c in ["fit","id","probability","overlap"] if c in num_cols]
X = df[num_cols].drop(columns=drop_cols)

print("Features:", X.shape[1], "| Taux de positifs:", round(y.mean(), 3))

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve
import matplotlib.pyplot as plt

RANDOM_STATE = 42

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.20, stratify=y, random_state=RANDOM_STATE
)

baseline = Pipeline([
    ("scaler", StandardScaler(with_mean=False)),
    ("clf", LogisticRegression(max_iter=2000, class_weight="balanced", random_state=RANDOM_STATE))
])
baseline.fit(X_train, y_train)

y_prob = baseline.predict_proba(X_test)[:, 1]
y_pred = (y_prob >= 0.5).astype(int)

print("=== Baseline Test metrics ===")
print("Accuracy:", round(accuracy_score(y_test, y_pred), 4))
print("ROC-AUC :", round(roc_auc_score(y_test, y_prob), 4))
print(confusion_matrix(y_test, y_pred))

fpr, tpr, _ = roc_curve(y_test, y_prob)
plt.plot(fpr, tpr); plt.plot([0,1],[0,1], "--"); plt.title("ROC — Baseline"); plt.show()

# On supprime les colonnes skills très rares (sum < MIN_FREQ) dans X_train
MIN_FREQ = 10  # essaie 5, 10, 15, 20
col_sums = X_train.sum(axis=0)
mask_keep = (col_sums >= MIN_FREQ) | (~X_train.columns.str.contains(r"^(req_|cand_|miss_)"))
cols_keep = X_train.columns[mask_keep]

X_train2 = X_train[cols_keep]
X_test2  = X_test[cols_keep]

pipe2 = Pipeline([
    ("scaler", StandardScaler(with_mean=False)),
    ("clf", LogisticRegression(max_iter=5000, class_weight="balanced", random_state=RANDOM_STATE))
])
pipe2.fit(X_train2, y_train)

# Recalcule seuil optimal sur validation (refaire split val)
X_tr2, X_val2, y_tr2, y_val2 = train_test_split(
    X_train2, y_train, test_size=0.25, stratify=y_train, random_state=RANDOM_STATE
)
pipe2.fit(X_tr2, y_tr2)
val_prob2 = pipe2.predict_proba(X_val2)[:, 1]
grid = np.linspace(0.2, 0.8, 121)
accs2 = [accuracy_score(y_val2, (val_prob2 >= t).astype(int)) for t in grid]
best_thr2 = float(grid[int(np.argmax(accs2))])

test_prob2 = pipe2.predict_proba(X_test2)[:, 1]
test_pred2 = (test_prob2 >= best_thr2).astype(int)

print("=== Test after rare-feature filter ===")
print("Accuracy:", round(accuracy_score(y_test, test_pred2), 4))
print("ROC-AUC :", round(roc_auc_score(y_test, test_prob2), 4))
print("Kept features:", len(cols_keep))

from sklearn.feature_selection import SelectFromModel
from sklearn.model_selection import StratifiedKFold, GridSearchCV

base_lr = LogisticRegression(
    solver="saga", penalty="elasticnet", l1_ratio=0.5,
    max_iter=6000, class_weight="balanced", random_state=RANDOM_STATE, n_jobs=-1
)

tuned = Pipeline([
    ("selector", SelectFromModel(LogisticRegression(
        solver="saga", penalty="l1", C=0.2, max_iter=5000,
        class_weight="balanced", random_state=RANDOM_STATE, n_jobs=-1
    ), prefit=False)),
    ("scaler", StandardScaler(with_mean=False)),
    ("clf", base_lr),
])

param_grid = {
    "selector__threshold": [None, "median"],  # None = pas de drop; "median" ≈ drop ~50% faibles
    "clf__l1_ratio": [0.2, 0.5, 0.8],
    "clf__C": [0.05, 0.1, 0.2, 0.5, 1.0],
}

cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)
gs = GridSearchCV(tuned, param_grid=param_grid, scoring="roc_auc", cv=cv, n_jobs=-1, refit=True, verbose=0)
gs.fit(X_train2, y_train)

print("Best params:", gs.best_params_, "| Best CV AUC:", round(gs.best_score_, 4))

# seuil optimal sur validation
X_tr3, X_val3, y_tr3, y_val3 = train_test_split(
    X_train2, y_train, test_size=0.25, stratify=y_train, random_state=RANDOM_STATE
)
best_pipe = gs.best_estimator_.fit(X_tr3, y_tr3)
val_prob3 = best_pipe.predict_proba(X_val3)[:, 1]
grid = np.linspace(0.2, 0.8, 121)
accs3 = [accuracy_score(y_val3, (val_prob3 >= t).astype(int)) for t in grid]
best_thr3 = float(grid[int(np.argmax(accs3))])

# test final
best_pipe.fit(X_train2, y_train)  # réentraine sur tout train
test_prob3 = best_pipe.predict_proba(X_test2)[:, 1]
test_pred3 = (test_prob3 >= best_thr3).astype(int)

print("=== Test after tuning (ElasticNet + L1) ===")
print("Accuracy:", round(accuracy_score(y_test, test_pred3), 4))
print("ROC-AUC :", round(roc_auc_score(y_test, test_prob3), 4))

import joblib, json

# Choisis la meilleure variante selon ton résultat :
MODEL = best_pipe
THRESH = best_thr3
FEATURES = X_train2.columns.tolist()

joblib.dump(MODEL, "/content/job_fit_best.pkl")
with open("/content/job_fit_best.json", "w") as f:
    json.dump({"feature_order": FEATURES, "best_threshold": float(THRESH)}, f, indent=2)

print("✅ Saved: /content/job_fit_best.pkl & /content/job_fit_best.json")